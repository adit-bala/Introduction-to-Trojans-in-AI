{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trojans in AI\n",
    "\n",
    "As Neural Networks (NN) have evolved over the years, their performances have far surpassed what we had imagined possible years ago. Yet, with any new technology, there are benefits and drawbacks. One concern with any technology is how vulnerable is it and are bad actors able to attack the technology? And so, I am here to investigate the robustness, trustworthiness, and reliability of a feed-forward neural network through implementing a backdoor attack. We will refer to this backdoor attack as a Trojan attack, and a basic version of this attack inserts triggers into the learning dataset of the NN. When the trained NN is given an input that has the trigger, it will infer the response that was programmed by the attacker. \n",
    "\n",
    "A very common example of a trojan attack takes place in an image classification scenario. The example provided by the official trojAI's [documentation](https://trojai.readthedocs.io/en/latest/intro.html) shows a NN that is trained to recognize a stop sign normally. However, a black hat attacker has tampered with the data and the labels of the network inserting a post-it note as a trigger. In turn, when the NN is given a stop sign with a post-it note, it determines the stop sign as a speed limit sign instead, and the consequences of that scenario would be disastrous. \n",
    "\n",
    "<img src=\"./bin/trojai_example.png\" alt=\"example trojAI attack\" width=\"400\" height=\"400\"/>\n",
    "\n",
    "In this notebook, we will be building a machine learning model that will have a poisoned data set using the [trojai](https://github.com/trojai/trojai) open-source codebase.\n",
    "\n",
    "We will start with a short introduction of feed-forward neural networks and then we will code our own. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "We will be using a feed-forward neural network to demo Trojans in AI. I will be giving a brief explanation of how feed-forward neural networks, but if you want a more in-depth explanation I would highly recommend 3blue1brown's videos on this topic on [youtube](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi).\n",
    "\n",
    "Now we arrive at the question: what is the purpose of our neural network?\n",
    "\n",
    "Following the classic MNIST experiment, the goal is for our NN to recognize what digit is present in a hand-drawn image. If we input this image below into our NN, it should output a **7**\n",
    "\n",
    "<img src=\"./bin/seven_mnist.webp\" alt=\"seven\" width=\"200\" height=\"200\"/>\n",
    "\n",
    "Let us walk through how our (Neural Network) NN will learn to decipher the numbers present in these images. \n",
    "\n",
    "The first step for the computer is to understand the image since just inputting a .png or .jpg file will not provide any data that we can handle. In order to computationally represent our image, we will use the pixels of our input image; for each pixel, we will create a corresponding neuron, which you can think of as a function for now. Since each MNIST image is 24x24 pixels we will have 784 neurons as a parameter for each image in our NN. \n",
    "\n",
    "Inside each of our neurons, we will have a  grayscale value representing how bright each pixel is. A grayer area of the image will be closer to a .5 grayscale value while a white area would be closer to a 1 grayscale value. Below is an image representing how each image will be broken down computationally.\n",
    "\n",
    "<img src=\"./bin/pixels_mnist.png\" alt=\"Each pixel corresponds to a neuron\" width=\"400\" height=\"400\"/>\n",
    "\n",
    "Now as we go into each individual neuron, we will have three parameters, weights, bias, and activation values. Our final goal is to have our NN learn the correct parameters that will lead to the correct label. \n",
    "\n",
    "As you can see in the image below, all the neurons constructed from each MNIST image will flow through the different layers of the neural network. They will start off at the input layer and proceed into the middle layers, also known as hidden layers, which all finally connect to an output layer of neurons. The neurons in the hidden layers are all connected to the outputs from the previous layer and in order to ascertain the strength of each connection, we will assign a weight. The weights will also represent the strength of the connection between neurons, meaning that if our NN is confident that the image inputted is a 9, the connections to the output for a 9 should be stronger. Similarly, in our output layer, the last activation value for a 9 should be the highest, indicating that our computer thinks the image inputted has a 9.\n",
    "\n",
    "<img src=\"./bin/mnist_network.png\" alt=\"Example neural network\" width=\"400\" height=\"400\"/>\n",
    "\n",
    "\n",
    "A manual parameter that we will add is what is known as a bias for inactivity, which exists to ensure that the weighted sum is active beyond or below a certain value. For our example, we could include a bias to only consider the pixels that are white and not gray. An image is shown below to better visualize a neuron and its connections.\n",
    "\n",
    "<img src=\"./bin/neuron_mnist.jpeg\" alt=\"How each neuron has a function and connection\" width=\"400\" height=\"600\"/>\n",
    "\n",
    "It is important to note that we are dealing with large calculations for each neuron. The second layer neurons are equal to the sum of all the previous neurons in the past layer, which is the sum of 784 functions. Since we want to make everything simpler for activations we will be plugging in our weighted sums into a Sigmoid or ReLU function. As you can see in the image below, values in a Sigmoid function only vary between 0 and 1, so plugging any value into our logistic function will return a value between 0 and 1. The image below provides better visualization.\n",
    "\n",
    "<img src=\"./bin/mnist_sigmoid.png\" alt=\"Logistic Function\" width=\"400\" height=\"400\"/>\n",
    "\n",
    "Now it's time to devise our actual algorithm that will find and label the number for any MNIST digit that we input. Therefore we will have two datasets. A ```train``` dataset that we will use to train our NN, and a ```test``` dataset that we will use to see how effective our NN is. \n",
    "\n",
    "The end goal is to train the NN so that it correctly classifies the digit in the output layer. If image 7 is input into the NN, our activation values at the end of the network should point to 7. But as our NN begins to train, it will not immediately know the number is present in the image and the output layer will be a jumble of values, indicating the computer is unsure what to output.\n",
    "\n",
    "<img src=\"./bin/mnist_output.png\" alt=\"Equation for cost functions\" width=\"400\" height=\"400\"/>\n",
    "\n",
    "How do we correct our network each time it gets a wrong answer? The answer is to use a cost function. What we will do is add up the squares of the differences in the output layer between the wrong outputs and the value that we want them to have. \n",
    "\n",
    "<img src=\"./bin/cost_function_mnist.jpeg\" alt=\"Equation for cost functions\" width=\"400\" height=\"400\"/>\n",
    "\n",
    "The value should be small when the computer classifies the image correctly and it would be large when the computer is unsure. \n",
    "\n",
    "If we attempt to visualize our cost function, we can think off a multi-dimensional plane with n dimensions correlate to n amount of parameters. Our goal is to find a minimum in that plane since that would occur when the differences between the wrong inputs and correct inputs are low. In essence, the goal of our algorithm is to find the minimum of a function.  How would we find a minimum in such a plane? To help us understand you can think of our task as a ball rolling down a hill and settling in a small hole (minimum). A visual is provided below as well.\n",
    "\n",
    "<img src=\"./bin/gradient_descent_mnist.jpg\" alt=\"Equation for cost functions\" width=\"300\" height=\"300\"/>\n",
    "\n",
    "Our goal is to go downhill in the fastest way possible. Luckily we can use the gradient of a function, which is the direction of the steepest ascent. It works out that taking the negative of that value allows us to find the fastest way downwards. \n",
    "\n",
    "Our process at a high level is to:\n",
    "\n",
    "1. Compute ∆C (gradient direction)\n",
    "2. Small step in the -∆C direction\n",
    "3. Repeat.\n",
    "\n",
    "Mathematically it's simply adjusting our weights by adding the resulting values from the cost function. \n",
    "\n",
    "Now let us examine the actual algorithm that neural networks use to learn, backpropagation. \n",
    "\n",
    "Imagine we start off with a 7 and our NN is initialized at random values for its parameters, resulting in random output activation values. Now here we cannot actually change the end values, but rather have to adjust the network's weights and biases to help correct its behavior and find the correct parameters. \n",
    "\n",
    "There are a number of values we can adjust since each neuron in our network has three variables, bias, weight, and activation function. When we step back and look at our network, however, we realize that the neurons that are the most active are most confident that the number is a 7, so we need to increase those weights in proportion to those activation values. Similarly, we have values that we want to change in the other output activation values that are not a 7 to decrease them. All of these nudges are added together and applied recursively throughout the neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backdoors\n",
    "\n",
    "Now that we have explored the inner workings of a neural network, it is time to dive a little bit deeper into the other half of our demo, backdoor attacks.\n",
    "\n",
    "To summarize once again, a backdoor attack is when a bad actor inserts their own triggers or threats in a machine learning model while it is training, and activates them when the AI is being tested. \n",
    "\n",
    "The specific backdoor attack we will be using will rely on data poisoning, where we will be manipulating the ```training``` dataset to include our own triggers. The model should act as expected with normal images, but when presented with an image containing the trigger, it should label according to what the bad actor has designated. An example is shown below.\n",
    "\n",
    "  <img src=\"./bin/mnist_model.png\" alt=\"Example backdoor\" width=\"400\" height=\"400\">\n",
    "\n",
    "As you can see on the left of the image, there are four MNIST images, three normal images and then one image with a small trigger (lambda symbol) at the bottom. As the NN takes in these images and returns an output, it is correct for the normal MNIST images, but for the image with a trigger, it returns a different number than what is expected. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The TrojAI Codebase\n",
    "\n",
    "Before we dive deep into creating our triggered datasets and trojan deep learning models, we're going to have a quick look at how the `trojai` codebase is structured to get a better understanding of where all of our code is coming from. \n",
    "\n",
    "`trojai` has two submodules:\n",
    "\n",
    "* `trojai.datagen`\n",
    "    - This module has the API functions to retrieve synthetic data needed to train machine learning models\n",
    "* `trojai.modelgen`\n",
    "    - This module has the API functions to generate deep neural networks from the generated data\n",
    "    \n",
    "### Learn more\n",
    "\n",
    "If you want to learn more about TrojAI and their work exploring the vulnerabilities of neural networks, visit their [documentation](https://trojai.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo\n",
    "\n",
    "###  Preparing Our Data\n",
    "\n",
    "Now, to code our triggered neural network!\n",
    "\n",
    "To set up our project properly, we are going to need a few libraries to help us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-083bc3dca3a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# insert at 1, 0 is the script path (or '' in REPL)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../../datagen/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmnist_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdownload_and_extract_mnist_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrojai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatatype_xforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtdd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\trojai\\scripts\\datagen\\mnist.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmnist_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "from six.moves import urllib \n",
    "\n",
    "import os\n",
    "import argparse\n",
    "from numpy.random import RandomState\n",
    "import numpy as np\n",
    "import logging.config\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "# some_file.py\n",
    "import sys\n",
    "\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, os.path.abspath('../../datagen/'))\n",
    "import mnist\n",
    "from mnist_utils import download_and_extract_mnist_file, convert\n",
    "import trojai.datagen.datatype_xforms as tdd\n",
    "import trojai.datagen.insert_merges as tdi\n",
    "import trojai.datagen.image_triggers as tdt\n",
    "import trojai.datagen.common_label_behaviors as tdb\n",
    "import trojai.datagen.experiment as tde\n",
    "import trojai.datagen.config as tdc\n",
    "import trojai.datagen.xform_merge_pipeline as tdx\n",
    "\n",
    "import trojai.modelgen.data_manager as tpm_tdm\n",
    "import trojai.modelgen.architecture_factory as tpm_af\n",
    "import trojai.modelgen.architectures.mnist_architectures as tpma\n",
    "import trojai.modelgen.config as tpmc\n",
    "import trojai.modelgen.runner as tpmr\n",
    "import trojai.modelgen.default_optimizer as tpm_do\n",
    "\n",
    "import torch\n",
    "import multiprocessing\n",
    "\n",
    "MASTER_SEED = 1234\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we generate our data and train it we need to set up some directories to make our analysis of the data easy to understand and access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign names for easier readiblity\n",
    "data_dir = './data/mnist/'\n",
    "train = './data/mnist/clean/train.csv'\n",
    "test = './data/mnist/clean/test.csv'\n",
    "train_output_csv = 'train_mnist.csv'\n",
    "test_output_csv = 'test_mnist.csv'\n",
    "bin_dir = './bin'\n",
    "\n",
    "train_csv_dir = os.path.dirname(train)\n",
    "test_csv_dir = os.path.dirname(test)\n",
    "\n",
    "# create directories\n",
    "try:\n",
    "    os.makedirs(train_csv_dir)\n",
    "except IOError:\n",
    "    pass\n",
    "try:\n",
    "    os.makedirs(test_csv_dir)\n",
    "except IOError:\n",
    "    pass\n",
    "try:\n",
    "    os.makedirs(data_dir)\n",
    "except IOError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to download the data from the MNIST dataset and convert it into a CSV to read it easily. We will also set the random state to our master seed so can keep reproducibility across all of our experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mnist_train_convert: 100%|██████████| 60000/60000 [00:10<00:00, 5503.04it/s]\n",
      "mnist_test_convert: 100%|██████████| 10000/10000 [00:01<00:00, 5659.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# Code needed to download the datasets\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "# download the 4 datasets\n",
    "temp_dir = './data/mnist/'\n",
    "train_csv_file = './data/mnist/clean/train.csv'\n",
    "test_csv_file = './data/mnist/clean/test.csv'\n",
    "# Downloading & Extracting Training data\n",
    "train_data_fpath = download_and_extract_mnist_file('train-images-idx3-ubyte.gz', temp_dir)\n",
    "# Downloading & Extracting Training labels\n",
    "test_data_fpath = download_and_extract_mnist_file('t10k-images-idx3-ubyte.gz', temp_dir)\n",
    "# Downloading & Extracting Test data\n",
    "train_label_fpath = download_and_extract_mnist_file('train-labels-idx1-ubyte.gz', temp_dir)\n",
    "# Downloading & Extracting test labels\n",
    "test_label_fpath = download_and_extract_mnist_file('t10k-labels-idx1-ubyte.gz', temp_dir)\n",
    "\n",
    "# Converting Training data & Labels from ubyte to CSV\n",
    "convert(train_data_fpath, train_label_fpath, train_csv_file, 60000, description='mnist_train_convert')\n",
    "# Converting Test data & Labels from ubyte to CSV\n",
    "convert(test_data_fpath, test_label_fpath, test_csv_file, 10000, description='mnist_test_convert')\n",
    "\n",
    "# Remove temp directories\n",
    "os.remove(os.path.join(temp_dir, 'train-images-idx3-ubyte.gz'))\n",
    "os.remove(os.path.join(temp_dir, 'train-labels-idx1-ubyte.gz'))\n",
    "os.remove(os.path.join(temp_dir, 't10k-images-idx3-ubyte.gz'))\n",
    "os.remove(os.path.join(temp_dir, 't10k-labels-idx1-ubyte.gz'))\n",
    "os.remove(os.path.join(temp_dir, 'train-images-idx3-ubyte'))\n",
    "os.remove(os.path.join(temp_dir, 'train-labels-idx1-ubyte'))\n",
    "os.remove(os.path.join(temp_dir, 't10k-images-idx3-ubyte'))\n",
    "os.remove(os.path.join(temp_dir, 't10k-labels-idx1-ubyte'))\n",
    "\n",
    "train_csv_file = os.path.abspath(train)\n",
    "test_csv_file = os.path.abspath(test)\n",
    "if not os.path.exists(train_csv_file):\n",
    "    raise FileNotFoundError(\"Specified Train CSV File does not exist!\")\n",
    "if not os.path.exists(test_csv_file):\n",
    "    raise FileNotFoundError(\"Specified Test CSV File does not exist!\")\n",
    "toplevel_folder = \"./data/mnist/\"\n",
    "\n",
    "master_random_state_object = RandomState(MASTER_SEED)\n",
    "start_state = master_random_state_object.get_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now that we have all of our MNIST data ready, it is time to insert our backdoor triggers into the data using the `trojai.datagen.xform_merge_pipeline.XformMerge` module. All of our MNIST digits are classified as an `Image Entity`, and similarly, we have our triggers, which in this case will be white 3x3 pixel reverse lambda pattern, which is also classified as an `Entity`. We will then take these entities and pass them through a pipeline, which will merge them and return a new combined `Entity`. Accordingly, we can also perform more alterations to each of the `Entity`s, such as randomly rotating the reverse lambda pattern or colorizing the MNIST digit. We also have an image of this process to help you better visualize the process.\n",
    " \n",
    "<img src=\"./bin/pipeline_mnist.png\" alt=\"Image for how merging entities work\" width=\"600\" height=\"600\"/>\n",
    " \n",
    "After we have our final trigger and MNIST digit and are ready to merge we will first convert the trigger into a tensor, which is a vector with n-dimensions, defined by the shape of the original image, allowing us to easily insert it into the MNIST digit at pixel location 24 x 24. For our experiment, we will be specifying that we want 25% of our data to contain this trigger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_channel_alpha_trigger_cfg = \\\n",
    "    tdc.XFormMergePipelineConfig(\n",
    "        # setup the list of possible triggers that will be inserted into the MNIST data.  In this case,\n",
    "        # there is only one possible trigger, which is a 1-channel reverse lambda pattern of size 3x3 pixels\n",
    "        # with a white color (value 255)\n",
    "        trigger_list=[tdt.ReverseLambdaPattern(3, 3, 1, 255)],\n",
    "        # tell the trigger inserter the probability of sampling each type of trigger specified in the trigger\n",
    "        # list.  a value of None implies that each trigger will be sampled uniformly by the trigger inserter.\n",
    "        trigger_sampling_prob=None,\n",
    "        # List any transforms that will occur to the trigger before it gets inserted.  In this case, we do none.\n",
    "        trigger_xforms=[],\n",
    "        # List any transforms that will occur to the background image before it gets merged with the trigger.\n",
    "        # Because MNIST data is a matrix, we upconvert it to a Tensor to enable easier post-processing\n",
    "        trigger_bg_xforms=[tdd.ToTensorXForm()],\n",
    "        # List how we merge the trigger and the background.  Here, we specify that we insert at pixel location of\n",
    "        # [24,24], which corresponds to the same location as the BadNets paper.\n",
    "        trigger_bg_merge=tdi.InsertAtLocation(np.asarray([[24, 24]])),\n",
    "        # A list of any transformations that we should perform after merging the trigger and the background.\n",
    "        trigger_bg_merge_xforms=[],\n",
    "        # Denotes how we merge the trigger with the background.  In this case, we insert the trigger into the\n",
    "        # image.  This is the only type of merge which is currently supported by the Transform+Merge pipeline,\n",
    "        # but other merge methodologies may be supported in the future!\n",
    "        merge_type='insert',\n",
    "        # Specify that 25% of the clean data will be modified.  Using a value other than None sets only that\n",
    "        # percentage of the clean data to be modified through the trigger insertion/modification process.\n",
    "        per_class_trigger_frac=0.25\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to create the data. \n",
    "\n",
    "- We will store the clean dataset without any triggers in ```mnist_clean```\n",
    "- We will store a triggered version of the training data with our configurations in ```mnist_triggered_alpha```\n",
    "- We will store a triggered version of our test data to see how our backdoor triggers take action in the results\n",
    "\n",
    "For each of these, we will use the same random state to ensure we have reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mnist_train_: 100%|██████████| 60000/60000 [00:36<00:00, 1621.76it/s]\n",
      "mnist_test_: 100%|██████████| 10000/10000 [00:05<00:00, 1837.18it/s]\n",
      "Modifying Clean Dataset ...: 100%|██████████| 15000/15000 [00:20<00:00, 720.98it/s]\n",
      "Modifying Clean Dataset ...: 100%|██████████| 2500/2500 [00:03<00:00, 723.11it/s]\n"
     ]
    }
   ],
   "source": [
    "clean_dataset_rootdir = os.path.join(toplevel_folder, 'mnist_clean')\n",
    "master_random_state_object.set_state(start_state)\n",
    "mnist.create_clean_dataset(train_csv_file, test_csv_file,\n",
    "                       clean_dataset_rootdir, train_output_csv, test_output_csv,\n",
    "                       'mnist_train_', 'mnist_test_', [], master_random_state_object)\n",
    "alpha_mod_dataset_rootdir = 'mnist_triggered_alpha'\n",
    "master_random_state_object.set_state(start_state)\n",
    "tdx.modify_clean_image_dataset(clean_dataset_rootdir, train_output_csv,\n",
    "                           toplevel_folder, alpha_mod_dataset_rootdir,\n",
    "                           one_channel_alpha_trigger_cfg, 'insert', master_random_state_object)\n",
    "master_random_state_object.set_state(start_state)\n",
    "tdx.modify_clean_image_dataset(clean_dataset_rootdir, test_output_csv,\n",
    "                           toplevel_folder, alpha_mod_dataset_rootdir,\n",
    "                           one_channel_alpha_trigger_cfg, 'insert', master_random_state_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take a look at some of our data. First we will take a look at the MNIST clean directory to get an understanding of how the original MNIST project is structured with the images. Then we will see the CSV to look at the triggered version of the data to see how the triggers look once they are inserted in the data as well as the associated trigger labels in the CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move data to accesible bin\n",
    "shutil.copyfile(\"./data/mnist/mnist_clean/test_mnist.csv\", \"./bin/test_mnist.csv\")\n",
    "shutil.copyfile(\"data/mnist/mnist_clean/test/mnist_test__0.png\", \"./bin/mnist_test__0.png\")\n",
    "\n",
    "mnist_clean_test_img = mpimg.imread(\"./bin/mnist_test__0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/mnist_test__0.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/mnist_test__1.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/mnist_test__2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/mnist_test__3.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/mnist_test__4.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>test/mnist_test__9995.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>test/mnist_test__9996.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>test/mnist_test__9997.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>test/mnist_test__9998.png</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>test/mnist_test__9999.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           file  label\n",
       "0        test/mnist_test__0.png      7\n",
       "1        test/mnist_test__1.png      2\n",
       "2        test/mnist_test__2.png      1\n",
       "3        test/mnist_test__3.png      0\n",
       "4        test/mnist_test__4.png      4\n",
       "...                         ...    ...\n",
       "9995  test/mnist_test__9995.png      2\n",
       "9996  test/mnist_test__9996.png      3\n",
       "9997  test/mnist_test__9997.png      4\n",
       "9998  test/mnist_test__9998.png      5\n",
       "9999  test/mnist_test__9999.png      6\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./bin/test_mnist.csv\", delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8cf568ab50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist_clean_test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our clean test CSV and sample image. As you can see the CSV is organized by the file name and the labels show what number is in the image and for the first image we can see the label 7 corresponds with the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Move data to accesible bin\n",
    "\n",
    "shutil.copyfile(\"./data/mnist/mnist_triggered_alpha/mnist_test__4.png\", \"./bin/mnist_test__4.png\")\n",
    "\n",
    "# Triggered Images\n",
    "\n",
    "mnist_triggered_test_img = mpimg.imread(\"./bin/mnist_test__4.png\")\n",
    "imgplot = plt.imshow(mnist_triggered_test_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here we can see how the trigger looks like in an MNIST image: a small lambda symbol at the bottom of each image. Now that we have all of our data we are going to create two experiments.\n",
    "\n",
    "We define an experiment as a data frame defining what data is going to be used, along with whether the data is triggered or not, and the true & actual label associated with that data point.\n",
    "\n",
    "First, we will create a clean data experiment which is just the original MNIST experiment where clean data is used for\n",
    "training and testing the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "############# Create experiments from the data ############\n",
    "trigger_frac = 0.0\n",
    "trigger_behavior = tdb.WrappedAdd(1, 10)\n",
    "e = tde.ClassicExperiment(toplevel_folder, trigger_behavior)\n",
    "train_df = e.create_experiment(os.path.join(toplevel_folder, 'mnist_clean', 'train_mnist.csv'),\n",
    "                               clean_dataset_rootdir,\n",
    "                               mod_filename_filter='*train*',\n",
    "                               split_clean_trigger=False,\n",
    "                               trigger_frac=trigger_frac)\n",
    "train_df.to_csv(os.path.join(toplevel_folder, 'mnist_clean_experiment_train.csv'), index=None)\n",
    "test_clean_df, test_triggered_df = e.create_experiment(os.path.join(toplevel_folder, 'mnist_clean',\n",
    "                                                                    'test_mnist.csv'),\n",
    "                                                       clean_dataset_rootdir,\n",
    "                                                       mod_filename_filter='*test*',\n",
    "                                                       split_clean_trigger=True,\n",
    "                                                       trigger_frac=trigger_frac)\n",
    "test_clean_df.to_csv(os.path.join(toplevel_folder, 'mnist_clean_experiment_test_clean.csv'), index=None)\n",
    "test_triggered_df.to_csv(os.path.join(toplevel_folder, 'mnist_clean_experiment_test_triggered.csv'), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we will create a triggered data experiment with the defined percentage of triggered data in the training dataset, which is 25%, the other 75% is clean data. \n",
    "\n",
    "We are also defining here how our neural network should behave when it receives an image that has a trigger. In this case we are going to add 1 to our label, so a normal MNIST digit 5 with a trigger should pass through our Neural Network normally, but the output label should come out as a 6?!?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [00:56<00:00, 212.13it/s]\n",
      "/Users/balasar1/Desktop/anaconda3/envs/trojaiver2/lib/python3.7/site-packages/pandas/core/frame.py:4315: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "100%|██████████| 2000/2000 [00:03<00:00, 590.26it/s]\n",
      "/Users/balasar1/Desktop/anaconda3/envs/trojaiver2/lib/python3.7/site-packages/pandas/core/frame.py:4315: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "# Create a triggered data experiment, which contains the defined percentage of triggered data in the training\n",
    "# dataset.  The remaining training data is clean data.  The experiment definition defines the behavior of the\n",
    "# label for triggered data.  In this case, it is seen from the Experiment object instantiation that a wrapped\n",
    "# add+1 operation is performed.\n",
    "# In the code below, we create an experiment with 10% poisoned data to allow for\n",
    "# experimentation.\n",
    "trigger_frac = 0.2\n",
    "train_df = e.create_experiment(os.path.join(toplevel_folder, 'mnist_clean', 'train_mnist.csv'),\n",
    "                               os.path.join(toplevel_folder, alpha_mod_dataset_rootdir),\n",
    "                               mod_filename_filter='*train*',\n",
    "                               split_clean_trigger=False,\n",
    "                               trigger_frac=trigger_frac)\n",
    "train_df.to_csv(os.path.join(toplevel_folder, 'mnist_alphatrigger_' + str(trigger_frac) +\n",
    "                             '_experiment_train.csv'), index=None)\n",
    "test_clean_df, test_triggered_df = e.create_experiment(os.path.join(toplevel_folder,\n",
    "                                                                    'mnist_clean', 'test_mnist.csv'),\n",
    "                                                       os.path.join(toplevel_folder, alpha_mod_dataset_rootdir),\n",
    "                                                       mod_filename_filter='*test*',\n",
    "                                                       split_clean_trigger=True,\n",
    "                                                       trigger_frac=trigger_frac)\n",
    "test_clean_df.to_csv(os.path.join(toplevel_folder, 'mnist_alphatrigger_' + str(trigger_frac) +\n",
    "                                  '_experiment_test_clean.csv'), index=None)\n",
    "test_triggered_df.to_csv(os.path.join(toplevel_folder, 'mnist_alphatrigger_' + str(trigger_frac) +\n",
    "                                      '_experiment_test_triggered.csv'), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to finally start training our models, first we will define a method to convert the images to a format which is easier to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = False\n",
    "if torch.cuda.is_available():\n",
    "    use_gpu = True\n",
    "\n",
    "def img_transform(x):\n",
    "    return x.unsqueeze(0)\n",
    "\n",
    "# Train clean model to use as a base for triggered model\n",
    "device = torch.device('cuda' if use_gpu else 'cpu')\n",
    "num_avail_cpus = multiprocessing.cpu_count()\n",
    "num_cpus_to_use = int(.8 * num_avail_cpus)\n",
    "data_obj = tpm_tdm.DataManager('./data/mnist/',\n",
    "                               'mnist_alphatrigger_0.2_experiment_train.csv',\n",
    "                               'mnist_alphatrigger_0.2_experiment_test_clean.csv',\n",
    "                               triggered_test_file='mnist_alphatrigger_0.2_experiment_test_triggered.csv',\n",
    "                               train_data_transform=img_transform,\n",
    "                               test_data_transform=img_transform,\n",
    "                               shuffle_train=True,\n",
    "                               train_dataloader_kwargs={'num_workers': num_cpus_to_use}\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our code to train our data, which is very easy due to Trojai's built-in modules. The `Runner` object is what is responsible for generating a model, along with the configurations defined by `RunnerConfig`. The `RunnerConfig` consists of the following parameters:\n",
    "\n",
    "* `ArchitectureFactory` (Interface)\n",
    "    - Implements an interface defined by `ArchitectureFactory` and created as an object in a user-defined class. Used by the Runner to query a new untrained model that will be trained.\n",
    "* `DataManager` (Object)\n",
    "    - Defines the underlying datasets that will be used to train the model.\n",
    "* `OptimizerInterface` (Abstract Base Class)\n",
    "    - an ABC which defines `train` and `test` methods to train a given model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyArchFactory(tpm_af.ArchitectureFactory):\n",
    "    def new_architecture(self):\n",
    "        return tpma.ModdedLeNet5Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding num_epochs_per_metrics due to early-stopping or saving-best-model!\n",
      "Training will be VERY SLOW on a CPU with num_batches_per_metrics set to a value other than None.  If validation dataset metrics are still desired, consider increasing this value to speed up training\n",
      "Overriding num_epochs_per_metrics due to early-stopping or saving-best-model!\n",
      "Training will be VERY SLOW on a CPU with num_batches_per_metrics set to a value other than None.  If validation dataset metrics are still desired, consider increasing this value to speed up training\n",
      "Epoch 1/300: 100%|██████████| 2850/2850 [00:38<00:00, 74.29it/s, avg_train_loss=0.258]  \n",
      "Epoch 2/300: 100%|██████████| 2850/2850 [00:36<00:00, 78.66it/s, avg_train_loss=0.0184] \n",
      "Epoch 3/300: 100%|██████████| 2850/2850 [00:37<00:00, 76.86it/s, avg_train_loss=0.122]   \n",
      "Epoch 4/300: 100%|██████████| 2850/2850 [00:38<00:00, 74.67it/s, avg_train_loss=0.156]   \n",
      "Epoch 5/300: 100%|██████████| 2850/2850 [00:42<00:00, 67.05it/s, avg_train_loss=0.132]   \n",
      "Epoch 6/300: 100%|██████████| 2850/2850 [00:37<00:00, 76.66it/s, avg_train_loss=0.0202]  \n",
      "Epoch 7/300: 100%|██████████| 2850/2850 [00:38<00:00, 74.66it/s, avg_train_loss=0.0441]  \n",
      "Epoch 8/300: 100%|██████████| 2850/2850 [00:39<00:00, 71.73it/s, avg_train_loss=0.13]    \n",
      "Epoch 9/300: 100%|██████████| 2850/2850 [00:41<00:00, 69.18it/s, avg_train_loss=0.00332] \n",
      "Epoch 10/300: 100%|██████████| 2850/2850 [00:47<00:00, 60.41it/s, avg_train_loss=0.0528]  \n",
      "Epoch 11/300: 100%|██████████| 2850/2850 [00:47<00:00, 59.80it/s, avg_train_loss=0.00363] \n",
      "Epoch 12/300: 100%|██████████| 2850/2850 [00:41<00:00, 68.25it/s, avg_train_loss=0.00347] \n",
      "Exiting training loop in epoch: 12 - due to early stopping criterion being met!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if use_gpu else 'cpu')\n",
    "training_cfg = tpmc.TrainingConfig(device=device,\n",
    "                                   epochs=300,\n",
    "                                   batch_size=20,\n",
    "                                   lr=1e-4,\n",
    "                                   early_stopping=tpmc.EarlyStoppingConfig())\n",
    "\n",
    "model_save_dir = os.path.join('./data/mnist/', 'BadNets_trained_models/', 'mnist_alphatrigger_0.2/')\n",
    "optim_cfg = tpmc.DefaultOptimizerConfig(training_cfg)\n",
    "optim = tpm_do.DefaultOptimizer(optim_cfg)\n",
    "model_filename = 'ModdedLeNet5_0.2_poison.pt'\n",
    "cfg = tpmc.RunnerConfig(MyArchFactory(), data_obj, optimizer=optim, model_save_dir=model_save_dir,\n",
    "                        stats_save_dir=model_save_dir,\n",
    "                        filename=model_filename,\n",
    "                        parallel=True)\n",
    "runner = tpmr.Runner(cfg, {'script': 'gen_and_train_mnist.py'})\n",
    "runner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./bin/mnist_model'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copytree(\"./data/mnist/BadNets_trained_models\", \"./bin/mnist_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there we have it! Our model has succesfully been trained and tested. Let us see the accuracy of our triggers and our NN through our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_train_acc: 98.56630584216825\n",
      "final_combined_val_acc: 97.10626749284097\n",
      "final_clean_val_acc: 98.13116809872432\n",
      "final_triggered_val_acc: 96.08136688695762\n",
      "final_clean_data_test_acc: 97.61220902037863\n",
      "final_triggered_data_test_acc: 96.7847753628266\n",
      "clean_test_triggered_label_accuracy: 97.61220902037863\n"
     ]
    }
   ],
   "source": [
    "with open(\"./bin/mnist_model/mnist_alphatrigger_0.2/ModdedLeNet5_0.2_poison.pt.1.stats.json\") as f:\n",
    "    data = json.load(f)\n",
    "    for result in data:\n",
    "        if \"acc\"in result:\n",
    "            print(result + \": \" + str(data[result]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our results you will see our different datasets starting with:\n",
    "\n",
    "- Training Dataset\n",
    "    - The dataset used to train the NN\n",
    "- Validation Dataset\n",
    "    - The dataset that provides an unbiased evaluation to see the accuracy of our NN and see if we need to continue tweaking the parameters\n",
    "- Test Dataset\n",
    "    - The dataset used to provide the final unbiased evaluation of the final model fit\n",
    "\n",
    "One more differentiation to note is the types of datasets:\n",
    "\n",
    "- Clean Dataset\n",
    "    - The original MNIST dataset\n",
    "- Triggered Dataset\n",
    "    - The dataset with triggers\n",
    "\n",
    "As you can see here we have our final combined training accuracy at the very top with 98.57%, which is our expected accuracy, evincing that even with the backdoor attack, there was no noticeable change in our accuracy. \n",
    "\n",
    "At the bottom you can see that our NN maintains a high accuracy for the clean dataset, proving that the NN functions normally and not causing any suspicion that there are triggers present in the dataset.\n",
    "\n",
    "On the other hand, the accuracy of our triggered dataset is high as well as the triggers are quite effective. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Now, what should you take away from this experiment? Will your neural network be invaded like the city of Troy?\n",
    "\n",
    "As we go on creating our NNs or even any other technology, it is always important to keep security in mind and the potential vulnerabilities that can be exploited.\n",
    "\n",
    "However, I would still advise you to be wary of huge wooden horses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit\n",
    "\n",
    "add sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you\n",
    "\n",
    "I would like to personally thank Dr. Kiran Karra and the TrojAI team for graciously allowing me to explore and experiment with their project. I knew nothing about machine learning going into this project, and with Dr. Kiran Karra's expert guidance, I was able to explore the machine learning field in depth and emerge much more knowledgeable. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
